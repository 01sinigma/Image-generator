"""
–ú–æ–¥—É–ª—å –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–ª–Ω–æ—Ç—ã –º–æ–¥–µ–ª–∏ –∏ –¥–æ–∫–∞—á–∫–∏ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤
"""

import os
import json
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from huggingface_hub import hf_hub_download, list_repo_files, repo_info
import time

logger = logging.getLogger(__name__)


class ModelCompletenessChecker:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –º–æ–¥–µ–ª–∏ –∏ –¥–æ–∫–∞—á–∫–∞ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤"""
    
    def __init__(self, model_name: str, local_path: Optional[str] = None):
        """
        Args:
            model_name: –ò–º—è –º–æ–¥–µ–ª–∏ –Ω–∞ Hugging Face (–Ω–∞–ø—Ä–∏–º–µ—Ä, "Qwen/Qwen-Image-Edit-2511")
            local_path: –õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        """
        self.model_name = model_name
        self.local_path = local_path
        self.repo_id = model_name
        self.missing_files = []
        self.incomplete_files = []
        
    def check_model_completeness(self) -> Tuple[bool, Dict]:
        """
        –î–µ—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –º–æ–¥–µ–ª–∏
        
        Returns:
            (is_complete, report) - –ø–æ–ª–Ω–∞—è –ª–∏ –º–æ–¥–µ–ª—å –∏ –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        """
        logger.info("=" * 60)
        logger.info("üîç –ù–∞—á–∏–Ω–∞—é –¥–µ—Ç–∞–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –ø–æ–ª–Ω–æ—Ç—ã –º–æ–¥–µ–ª–∏...")
        logger.info(f"–ú–æ–¥–µ–ª—å: {self.model_name}")
        logger.info("=" * 60)
        
        report = {
            "model_index": False,
            "components": {},
            "total_files": 0,
            "found_files": 0,
            "missing_files": [],
            "incomplete_files": []
        }
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ model_index.json
        model_index_path = None
        if self.local_path:
            model_index_path = os.path.join(self.local_path, "model_index.json")
            if os.path.exists(model_index_path):
                report["model_index"] = True
                logger.info("‚úÖ model_index.json –Ω–∞–π–¥–µ–Ω")
            else:
                logger.warning("‚ùå model_index.json –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
                self.missing_files.append("model_index.json")
        else:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ –∫—ç—à–µ Hugging Face
            try:
                from huggingface_hub import scan_cache_dir
                cache_info = scan_cache_dir()
                for repo in cache_info.repos:
                    if self.model_name.split('/')[-1].lower() in str(repo.repo_id).lower():
                        # –ú–æ–¥–µ–ª—å –µ—Å—Ç—å –≤ –∫—ç—à–µ, –Ω–æ –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∞–π–ª—ã
                        logger.info(f"–ú–æ–¥–µ–ª—å –Ω–∞–π–¥–µ–Ω–∞ –≤ –∫—ç—à–µ: {repo.repo_id}")
                        break
            except:
                pass
        
        # –ï—Å–ª–∏ model_index.json –Ω–∞–π–¥–µ–Ω, —á–∏—Ç–∞–µ–º –µ–≥–æ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        if model_index_path and os.path.exists(model_index_path):
            try:
                with open(model_index_path, 'r', encoding='utf-8') as f:
                    model_index = json.load(f)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
                components_to_check = [
                    "text_encoder", "text_encoder_2",
                    "vae", "vae_decoder", "vae_encoder",
                    "unet", "transformer",
                    "scheduler", "tokenizer", "tokenizer_2"
                ]
                
                for component in components_to_check:
                    if component in model_index:
                        component_path = model_index[component]
                        if isinstance(component_path, list):
                            component_path = component_path[0] if component_path else None
                        
                        if component_path:
                            report["components"][component] = self._check_component(
                                component, component_path
                            )
                            report["total_files"] += report["components"][component].get("total_files", 0)
                            report["found_files"] += report["components"][component].get("found_files", 0)
                            
                            if report["components"][component].get("missing_files"):
                                report["missing_files"].extend(
                                    report["components"][component]["missing_files"]
                                )
                            if report["components"][component].get("incomplete_files"):
                                report["incomplete_files"].extend(
                                    report["components"][component]["incomplete_files"]
                                )
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ model_index.json: {e}")
        
        # –ï—Å–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø—É—Ç–∏ –Ω–µ—Ç, –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ Hugging Face API
        if not self.local_path:
            logger.info("–õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –Ω–µ —É–∫–∞–∑–∞–Ω, –ø—Ä–æ–≤–µ—Ä—è—é —á–µ—Ä–µ–∑ Hugging Face API...")
            try:
                files_info = list_repo_files(repo_id=self.repo_id, repo_type="model")
                logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(files_info)} —Ñ–∞–π–ª–æ–≤ –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
                critical_files = [
                    "model_index.json",
                    "scheduler/scheduler_config.json",
                    "text_encoder/config.json"
                ]
                
                for critical_file in critical_files:
                    if any(critical_file in f for f in files_info):
                        logger.info(f"‚úÖ {critical_file} –Ω–∞–π–¥–µ–Ω –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏")
                    else:
                        logger.warning(f"‚ùå {critical_file} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏")
                        self.missing_files.append(critical_file)
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —á–µ—Ä–µ–∑ API: {e}")
        
        # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        is_complete = (
            report["model_index"] and
            len(report["missing_files"]) == 0 and
            len(report["incomplete_files"]) == 0
        )
        
        logger.info("=" * 60)
        logger.info("üìä –ò—Ç–æ–≥–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏:")
        logger.info(f"  –§–∞–π–ª–æ–≤ –≤—Å–µ–≥–æ: {report['total_files']}")
        logger.info(f"  –§–∞–π–ª–æ–≤ –Ω–∞–π–¥–µ–Ω–æ: {report['found_files']}")
        logger.info(f"  –§–∞–π–ª–æ–≤ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç: {len(report['missing_files'])}")
        logger.info(f"  –§–∞–π–ª–æ–≤ –Ω–µ–ø–æ–ª–Ω—ã—Ö: {len(report['incomplete_files'])}")
        logger.info(f"  –ú–æ–¥–µ–ª—å –ø–æ–ª–Ω–∞—è: {'‚úÖ –î–ê' if is_complete else '‚ùå –ù–ï–¢'}")
        logger.info("=" * 60)
        
        if report["missing_files"]:
            logger.warning("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã:")
            for f in report["missing_files"][:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                logger.warning(f"  - {f}")
            if len(report["missing_files"]) > 10:
                logger.warning(f"  ... –∏ –µ—â–µ {len(report['missing_files']) - 10} —Ñ–∞–π–ª–æ–≤")
        
        if report["incomplete_files"]:
            logger.warning("–ù–µ–ø–æ–ª–Ω—ã–µ —Ñ–∞–π–ª—ã:")
            for f in report["incomplete_files"][:10]:
                logger.warning(f"  - {f}")
            if len(report["incomplete_files"]) > 10:
                logger.warning(f"  ... –∏ –µ—â–µ {len(report['incomplete_files']) - 10} —Ñ–∞–π–ª–æ–≤")
        
        return is_complete, report
    
    def _check_component(self, component_name: str, component_path: str) -> Dict:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –º–æ–¥–µ–ª–∏"""
        logger.info(f"\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞: {component_name}")
        
        component_report = {
            "exists": False,
            "total_files": 0,
            "found_files": 0,
            "missing_files": [],
            "incomplete_files": []
        }
        
        if not self.local_path:
            return component_report
        
        # –ü—É—Ç—å –∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—É
        component_dir = os.path.join(self.local_path, component_name)
        
        if not os.path.exists(component_dir):
            logger.warning(f"  ‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {component_name} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
            component_report["missing_files"].append(f"{component_name}/")
            return component_report
        
        component_report["exists"] = True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º index —Ñ–∞–π–ª—ã (–¥–ª—è sharded –º–æ–¥–µ–ª–µ–π)
        index_files = [
            "model.safetensors.index.json",
            "model.safetensors.index",
            "pytorch_model.bin.index.json",
            "pytorch_model.bin.index"
        ]
        
        index_file_path = None
        for index_file in index_files:
            potential_path = os.path.join(component_dir, index_file)
            if os.path.exists(potential_path):
                index_file_path = potential_path
                logger.info(f"  ‚úÖ –ù–∞–π–¥–µ–Ω index —Ñ–∞–π–ª: {index_file}")
                break
        
        if index_file_path:
            # –≠—Ç–æ sharded –º–æ–¥–µ–ª—å - –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –∏–∑ index
            try:
                with open(index_file_path, 'r', encoding='utf-8') as f:
                    index_data = json.load(f)
                
                weight_map = index_data.get("weight_map", {})
                component_report["total_files"] = len(weight_map)
                
                # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤
                unique_files = set(weight_map.values())
                component_report["total_files"] = len(unique_files)
                
                logger.info(f"  üì¶ Sharded –º–æ–¥–µ–ª—å: {len(unique_files)} —Ñ–∞–π–ª–æ–≤ –≤–µ—Å–æ–≤")
                
                for weight_file in unique_files:
                    weight_file_path = os.path.join(component_dir, weight_file)
                    if os.path.exists(weight_file_path):
                        file_size = os.path.getsize(weight_file_path)
                        if file_size > 0:
                            component_report["found_files"] += 1
                            logger.debug(f"    ‚úÖ {weight_file} ({file_size / (1024**2):.1f} MB)")
                        else:
                            component_report["incomplete_files"].append(f"{component_name}/{weight_file}")
                            logger.warning(f"    ‚ö†Ô∏è {weight_file} –ø—É—Å—Ç–æ–π (0 bytes)")
                    else:
                        component_report["missing_files"].append(f"{component_name}/{weight_file}")
                        logger.warning(f"    ‚ùå {weight_file} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
            except Exception as e:
                logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ index —Ñ–∞–π–ª–∞: {e}")
        else:
            # –û–¥–∏–Ω–æ—á–Ω—ã–π —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏
            single_files = [
                "model.safetensors",
                "pytorch_model.bin",
                "diffusion_pytorch_model.safetensors",
                "diffusion_pytorch_model.bin"
            ]
            
            found_single = False
            for single_file in single_files:
                single_file_path = os.path.join(component_dir, single_file)
                if os.path.exists(single_file_path):
                    file_size = os.path.getsize(single_file_path)
                    component_report["total_files"] = 1
                    if file_size > 0:
                        component_report["found_files"] = 1
                        found_single = True
                        logger.info(f"  ‚úÖ {single_file} –Ω–∞–π–¥–µ–Ω ({file_size / (1024**2):.1f} MB)")
                        break
                    else:
                        component_report["incomplete_files"].append(f"{component_name}/{single_file}")
                        logger.warning(f"  ‚ö†Ô∏è {single_file} –ø—É—Å—Ç–æ–π")
                        break
            
            if not found_single:
                component_report["missing_files"].append(f"{component_name}/model.*")
                logger.warning(f"  ‚ùå –§–∞–π–ª—ã –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º config.json
        config_path = os.path.join(component_dir, "config.json")
        if not os.path.exists(config_path):
            component_report["missing_files"].append(f"{component_name}/config.json")
            logger.warning(f"  ‚ùå config.json –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
        else:
            logger.info(f"  ‚úÖ config.json –Ω–∞–π–¥–µ–Ω")
        
        return component_report
    
    def download_missing_files(self, report: Dict, max_retries: int = 3) -> bool:
        """
        –î–æ–∫–∞—á–∫–∞ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤
        
        Args:
            report: –û—Ç—á–µ—Ç –æ –ø—Ä–æ–≤–µ—Ä–∫–µ –º–æ–¥–µ–ª–∏
            max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
        
        Returns:
            True –µ—Å–ª–∏ –≤—Å–µ —Ñ–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω—ã
        """
        if not report["missing_files"] and not report["incomplete_files"]:
            logger.info("‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã –Ω–∞ –º–µ—Å—Ç–µ, –¥–æ–∫–∞—á–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
            return True
        
        logger.info("=" * 60)
        logger.info("üì• –ù–∞—á–∏–Ω–∞—é –¥–æ–∫–∞—á–∫—É –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤...")
        logger.info(f"–§–∞–π–ª–æ–≤ –¥–ª—è –¥–æ–∫–∞—á–∫–∏: {len(report['missing_files']) + len(report['incomplete_files'])}")
        logger.info("=" * 60)
        
        all_success = True
        
        # –î–æ–∫–∞—á–∏–≤–∞–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã
        for file_path in report["missing_files"]:
            logger.info(f"\nüì• –ó–∞–≥—Ä—É–∑–∫–∞: {file_path}")
            success = self._download_file_with_retry(file_path, max_retries)
            if not success:
                all_success = False
                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å: {file_path}")
        
        # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –Ω–µ–ø–æ–ª–Ω—ã–µ —Ñ–∞–π–ª—ã
        for file_path in report["incomplete_files"]:
            logger.info(f"\nüîÑ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–ø–æ–ª–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {file_path}")
            # –£–¥–∞–ª—è–µ–º –Ω–µ–ø–æ–ª–Ω—ã–π —Ñ–∞–π–ª
            if self.local_path:
                full_path = os.path.join(self.local_path, file_path)
                if os.path.exists(full_path):
                    try:
                        os.remove(full_path)
                        logger.info(f"  –£–¥–∞–ª–µ–Ω –Ω–µ–ø–æ–ª–Ω—ã–π —Ñ–∞–π–ª: {file_path}")
                    except Exception as e:
                        logger.warning(f"  –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª: {e}")
            
            success = self._download_file_with_retry(file_path, max_retries)
            if not success:
                all_success = False
                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å: {file_path}")
        
        if all_success:
            logger.info("=" * 60)
            logger.info("‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
            logger.info("=" * 60)
        else:
            logger.warning("=" * 60)
            logger.warning("‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ–∞–π–ª—ã –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å")
            logger.warning("=" * 60)
        
        return all_success
    
    def _download_file_with_retry(self, file_path: str, max_retries: int = 3) -> bool:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
        for attempt in range(1, max_retries + 1):
            try:
                logger.info(f"  –ü–æ–ø—ã—Ç–∫–∞ {attempt}/{max_retries}...")
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å
                local_file = None
                if self.local_path:
                    local_file = os.path.join(self.local_path, file_path)
                    os.makedirs(os.path.dirname(local_file), exist_ok=True)
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª
                downloaded_path = hf_hub_download(
                    repo_id=self.repo_id,
                    filename=file_path,
                    local_dir=self.local_path,
                    resume_download=True,
                    local_dir_use_symlinks=False
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
                if os.path.exists(downloaded_path):
                    file_size = os.path.getsize(downloaded_path)
                    if file_size > 0:
                        logger.info(f"  ‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {file_path} ({file_size / (1024**2):.1f} MB)")
                        return True
                    else:
                        logger.warning(f"  ‚ö†Ô∏è –§–∞–π–ª –ø—É—Å—Ç–æ–π, –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞...")
                        if os.path.exists(downloaded_path):
                            os.remove(downloaded_path)
                
            except Exception as e:
                logger.warning(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ (–ø–æ–ø—ã—Ç–∫–∞ {attempt}/{max_retries}): {e}")
                if attempt < max_retries:
                    wait_time = 2 ** attempt  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞: 2s, 4s, 8s
                    logger.info(f"  ‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ {wait_time} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π...")
                    time.sleep(wait_time)
        
        return False

